{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook contains the analysis to find impactful features\n",
    "This also explore the Normalization and the outcome is used in dataloader to generate normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import DataLoader\n",
    "from neuralnetwork import create_nn_regressor\n",
    "from configurations import args\n",
    "from base_regressor_plot import BaseRegressorPlot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis showed these features are impactful\n",
    "categorical_features = ['MSSubClass', 'MSZoning', 'LotShape',\n",
    "                        'LandContour', 'LotConfig', 'LandSlope', \n",
    "                        'Neighborhood', 'Condition1', 'Condition2',\n",
    "                        'BldgType', 'HouseStyle', 'RoofStyle', 'Heating',\n",
    "                        'HeatingQC']\n",
    "nominal_features = ['2ndFlrSF', '1stFlrSF', 'PoolArea', 'YearRemodAdd', \n",
    "                    'MasVnrArea', 'YearBuilt', 'KitchenAbvGr',\n",
    "                     'GrLivArea', 'OverallQual',\n",
    "                      'BedroomAbvGr', 'TotalBsmtSF', 'LotArea', \n",
    "                      'OverallCond',]\n",
    "                    \n",
    "full_list = nominal_features + categorical_features + ['SalePrice']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_loader.extract_features(full_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if there is any missing vairable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MasVnrArea    8\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def print_feature_with_na_vals():\n",
    "    '''This will count the na in each column and \n",
    "    print out the columns with NA and number of na in that column'''\n",
    "    number_of_na = df.isna().sum() \n",
    "    print(number_of_na[number_of_na > 0])\n",
    "print_feature_with_na_vals()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the number of NA in dataset showed that there are only 8 NA in MasVnrArea so we can drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dropping NA (1460, 28)\n",
      "After dropping NA (1452, 28), dropped 8\n"
     ]
    }
   ],
   "source": [
    "def drop_na_from_df(data):\n",
    "    before = data.shape[0]\n",
    "    print(f'Before dropping NA {data.shape}')\n",
    "    data = data.dropna()\n",
    "    print(f'After dropping NA {data.shape}, dropped {before - data.shape[0]}')\n",
    "    return data\n",
    "df = drop_na_from_df(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical Features with unique values which are unique in dataset will cause problem they need to be deleted since they create a std of zero either in the training set or the test set. This will break the normalization process.\n",
    "\n",
    "Note: We need to run the code multipe times since when dropping a row it might make another row with a single value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique value: PosA 1\n",
      "unique value: RRAn 1\n",
      "unique value: RRAe 1\n",
      "unique value: Floor 1\n",
      "unique value: Po 1\n",
      "is_unique_value_in_cat_features True\n",
      "Before dropping NA (1452, 28)\n",
      "removing: PosA 1\n",
      "removing: RRAn 1\n",
      "removing: RRAe 1\n",
      "removing: Shed 1\n",
      "removing: Floor 1\n",
      "removing: Po 1\n",
      "Before dropping NA (1446, 28), dropped 6\n"
     ]
    }
   ],
   "source": [
    "def is_unique_value_in_cat_features(data):\n",
    "    ''' This return '''\n",
    "    is_any_unique_value = False\n",
    "    for f in categorical_features:\n",
    "        if (data[f].value_counts() == 1).any():\n",
    "            for i, v in data[f].value_counts().items():\n",
    "                if v == 1:\n",
    "                    print('unique value:', i, v)\n",
    "            is_any_unique_value = True\n",
    "    return is_any_unique_value\n",
    "\n",
    "def remove_unique_value_of_cat_features(data):\n",
    "    before = data.shape[0]\n",
    "    print(f'Before dropping NA {data.shape}')\n",
    "    for f in categorical_features:\n",
    "        if (data[f].value_counts() == 1).any():\n",
    "            remove_list = []\n",
    "            for i, v in data[f].value_counts().items():\n",
    "                if v == 1:\n",
    "                    print('removing:', i, v)\n",
    "                    remove_list.append(i)\n",
    "            data = data[~data[f].isin(remove_list)]\n",
    "    print(f'Before dropping NA {data.shape}, dropped {before - data.shape[0]}')\n",
    "    return data\n",
    "\n",
    "\n",
    "print('is_unique_value_in_cat_features', is_unique_value_in_cat_features(df))\n",
    "df = remove_unique_value_of_cat_features(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Onehot Encoding is being used for categorical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xd/wdf8hgtn3wqg7n9q69rcsnx40000gn/T/ipykernel_47506/1024340132.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col_name] = (data_to_encode == cat_value) * 1.0\n"
     ]
    }
   ],
   "source": [
    "def encode_onehot(data, column_name):\n",
    "    ''' This onhot encode the categorical columns and drop the original column\n",
    "    \n",
    "    '''  \n",
    "    categorical_values = data[column_name].unique()\n",
    "    data_to_encode = data.pop(column_name)\n",
    "\n",
    "    for cat_value in categorical_values:\n",
    "        col_name = column_name+str(cat_value)\n",
    "        data[col_name] = (data_to_encode == cat_value) * 1.0\n",
    "\n",
    "\n",
    "def encode_cat_features(data, features):\n",
    "    for f in features:\n",
    "        encode_onehot(data, f)\n",
    "\n",
    "\n",
    "encode_cat_features(df, categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1446, 116)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data but since we need further analysis just combine back the Sales Price\n",
    "X_train, X_test, y_train, y_test = data_loader.split_data_df(\n",
    "    df, combine_back=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the correlation of nominal features and drop columns if they are highly correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_highly_corrlated_features(X_train, X_test):\n",
    "    X_train = X_train.drop(['1stFlrSF', '2ndFlrSF'], axis=1)\n",
    "    X_test = X_test.drop(['1stFlrSF', '2ndFlrSF'], axis=1)\n",
    "    # assuming this is final analysis so take out the Sales Proce\n",
    "    y_train = X_train.pop('SalePrice')\n",
    "    y_test = X_test.pop('SalePrice')\n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "X_train, X_test, y_train, y_test = drop_highly_corrlated_features(X_train, X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normilize Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First checking out the stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>...</th>\n",
       "      <th>RoofStyleFlat</th>\n",
       "      <th>HeatingGasA</th>\n",
       "      <th>HeatingGasW</th>\n",
       "      <th>HeatingGrav</th>\n",
       "      <th>HeatingWall</th>\n",
       "      <th>HeatingOthW</th>\n",
       "      <th>HeatingQCEx</th>\n",
       "      <th>HeatingQCGd</th>\n",
       "      <th>HeatingQCTA</th>\n",
       "      <th>HeatingQCFa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1156.000000</td>\n",
       "      <td>1156.000000</td>\n",
       "      <td>1156.000000</td>\n",
       "      <td>1156.000000</td>\n",
       "      <td>1156.000000</td>\n",
       "      <td>1156.000000</td>\n",
       "      <td>1156.000000</td>\n",
       "      <td>1156.000000</td>\n",
       "      <td>1156.000000</td>\n",
       "      <td>1156.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1156.000000</td>\n",
       "      <td>1156.000000</td>\n",
       "      <td>1156.000000</td>\n",
       "      <td>1156.000000</td>\n",
       "      <td>1156.000000</td>\n",
       "      <td>1156.000000</td>\n",
       "      <td>1156.000000</td>\n",
       "      <td>1156.000000</td>\n",
       "      <td>1156.000000</td>\n",
       "      <td>1156.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.555363</td>\n",
       "      <td>1985.167820</td>\n",
       "      <td>106.194637</td>\n",
       "      <td>1971.225779</td>\n",
       "      <td>1.046713</td>\n",
       "      <td>1513.214533</td>\n",
       "      <td>6.075260</td>\n",
       "      <td>2.865917</td>\n",
       "      <td>1055.370242</td>\n",
       "      <td>10354.016436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006055</td>\n",
       "      <td>0.982699</td>\n",
       "      <td>0.008651</td>\n",
       "      <td>0.003460</td>\n",
       "      <td>0.003460</td>\n",
       "      <td>0.001730</td>\n",
       "      <td>0.515571</td>\n",
       "      <td>0.165225</td>\n",
       "      <td>0.286332</td>\n",
       "      <td>0.032872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>39.271719</td>\n",
       "      <td>20.677768</td>\n",
       "      <td>183.807864</td>\n",
       "      <td>30.258255</td>\n",
       "      <td>0.211114</td>\n",
       "      <td>525.223273</td>\n",
       "      <td>1.382154</td>\n",
       "      <td>0.815551</td>\n",
       "      <td>436.827395</td>\n",
       "      <td>9478.614510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077614</td>\n",
       "      <td>0.130447</td>\n",
       "      <td>0.092645</td>\n",
       "      <td>0.058747</td>\n",
       "      <td>0.058747</td>\n",
       "      <td>0.041577</td>\n",
       "      <td>0.499974</td>\n",
       "      <td>0.371544</td>\n",
       "      <td>0.452242</td>\n",
       "      <td>0.178379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>334.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1967.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1953.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1126.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>795.750000</td>\n",
       "      <td>7500.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1994.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1972.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1467.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>9391.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>169.250000</td>\n",
       "      <td>2000.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1768.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1300.500000</td>\n",
       "      <td>11475.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>738.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5642.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6110.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          PoolArea  YearRemodAdd   MasVnrArea    YearBuilt  KitchenAbvGr  \\\n",
       "count  1156.000000   1156.000000  1156.000000  1156.000000   1156.000000   \n",
       "mean      2.555363   1985.167820   106.194637  1971.225779      1.046713   \n",
       "std      39.271719     20.677768   183.807864    30.258255      0.211114   \n",
       "min       0.000000   1950.000000     0.000000  1872.000000      1.000000   \n",
       "25%       0.000000   1967.000000     0.000000  1953.000000      1.000000   \n",
       "50%       0.000000   1994.500000     0.000000  1972.000000      1.000000   \n",
       "75%       0.000000   2004.000000   169.250000  2000.250000      1.000000   \n",
       "max     738.000000   2010.000000  1600.000000  2010.000000      2.000000   \n",
       "\n",
       "         GrLivArea  OverallQual  BedroomAbvGr  TotalBsmtSF        LotArea  \\\n",
       "count  1156.000000  1156.000000   1156.000000  1156.000000    1156.000000   \n",
       "mean   1513.214533     6.075260      2.865917  1055.370242   10354.016436   \n",
       "std     525.223273     1.382154      0.815551   436.827395    9478.614510   \n",
       "min     334.000000     1.000000      0.000000     0.000000    1300.000000   \n",
       "25%    1126.000000     5.000000      2.000000   795.750000    7500.000000   \n",
       "50%    1467.000000     6.000000      3.000000   990.000000    9391.000000   \n",
       "75%    1768.000000     7.000000      3.000000  1300.500000   11475.750000   \n",
       "max    5642.000000    10.000000      8.000000  6110.000000  215245.000000   \n",
       "\n",
       "       ...  RoofStyleFlat  HeatingGasA  HeatingGasW  HeatingGrav  HeatingWall  \\\n",
       "count  ...    1156.000000  1156.000000  1156.000000  1156.000000  1156.000000   \n",
       "mean   ...       0.006055     0.982699     0.008651     0.003460     0.003460   \n",
       "std    ...       0.077614     0.130447     0.092645     0.058747     0.058747   \n",
       "min    ...       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%    ...       0.000000     1.000000     0.000000     0.000000     0.000000   \n",
       "50%    ...       0.000000     1.000000     0.000000     0.000000     0.000000   \n",
       "75%    ...       0.000000     1.000000     0.000000     0.000000     0.000000   \n",
       "max    ...       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "       HeatingOthW  HeatingQCEx  HeatingQCGd  HeatingQCTA  HeatingQCFa  \n",
       "count  1156.000000  1156.000000  1156.000000  1156.000000  1156.000000  \n",
       "mean      0.001730     0.515571     0.165225     0.286332     0.032872  \n",
       "std       0.041577     0.499974     0.371544     0.452242     0.178379  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     1.000000     0.000000     0.000000     0.000000  \n",
       "75%       0.000000     1.000000     0.000000     1.000000     0.000000  \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  \n",
       "\n",
       "[8 rows x 113 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats():\n",
    "    stats = X_train.describe()\n",
    "    return stats.transpose()\n",
    "\n",
    "def normalize(data, stats):\n",
    "    return (data - stats['mean']) / stats['std']\n",
    "\n",
    "def get_normilze_data():\n",
    "    # using the same stats for both train and test\n",
    "    stats = get_stats()\n",
    "    norm_X_train = normalize(X_train, stats)\n",
    "    norm_X_test = normalize(X_test, stats)\n",
    "    return norm_X_train, norm_X_test\n",
    "\n",
    "\n",
    "norm_X_train, norm_X_test = get_normilze_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1156, 113), (290, 113), 113)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_X_train.shape, norm_X_test.shape, len(norm_X_train.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "If there was problem then some will be Nan because of divided to zero) so vefirying that there is no missing value after normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "norm_X_train.isna().values.any(), norm_X_test.isna().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is not NA value so normilzation was successful"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2ec5ef2ef6915d277aaea50dc172e794b982cc5f41075f1dfd6598edc485a9d8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('w207final': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
