{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook contains the analysis to find impactful features\n",
    "This also explore the Normalization and the outcome is used in dataloader to generate normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import DataLoader\n",
    "from configurations import args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis discoverd impactful feature in this analysis we evaluate them closely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "categorical_features = ['MSSubClass', 'MSZoning', 'LotShape',\n",
    "                        'LandContour', 'LotConfig', 'LandSlope', \n",
    "                        'Neighborhood', 'Condition1', 'Condition2',\n",
    "                        'BldgType', 'HouseStyle', 'RoofStyle', 'Heating',\n",
    "                        'HeatingQC']\n",
    "nominal_features = ['2ndFlrSF', '1stFlrSF', 'PoolArea', 'YearRemodAdd', \n",
    "                    'MasVnrArea', 'YearBuilt', 'KitchenAbvGr',\n",
    "                     'GrLivArea', 'OverallQual',\n",
    "                      'BedroomAbvGr', 'TotalBsmtSF', 'LotArea', \n",
    "                      'OverallCond',]\n",
    "                    \n",
    "full_list = nominal_features + categorical_features + ['SalePrice']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_loader.extract_features(full_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if there is any missing vairable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MasVnrArea    8\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def print_feature_with_na_vals():\n",
    "    '''This will count the na in each column and \n",
    "    print out the columns with NA and number of na in that column'''\n",
    "    number_of_na = df.isna().sum() \n",
    "    print(number_of_na[number_of_na > 0])\n",
    "print_feature_with_na_vals()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the number of NA in dataset showed that there are only 8 NA in MasVnrArea so we can drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dropping NA (1456, 28)\n",
      "After dropping NA (1448, 28), dropped 8\n"
     ]
    }
   ],
   "source": [
    "def drop_na_from_df(data):\n",
    "    before = data.shape[0]\n",
    "    print(f'Before dropping NA {data.shape}')\n",
    "    data = data.dropna()\n",
    "    print(f'After dropping NA {data.shape}, dropped {before - data.shape[0]}')\n",
    "    return data\n",
    "df = drop_na_from_df(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical Features with unique values which are unique in dataset will cause problem they need to be deleted since they create a std of zero either in the training set or the test set. This will break the normalization process.\n",
    "\n",
    "Note: We need to run the code multipe times since when dropping a row it might make another row with a single value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique value: PosA 1\n",
      "unique value: PosN 1\n",
      "unique value: RRAn 1\n",
      "unique value: RRAe 1\n",
      "unique value: Floor 1\n",
      "unique value: Po 1\n",
      "is_unique_value_in_cat_features True\n",
      "Before dropping NA (1448, 28)\n",
      "removing: PosA 1\n",
      "removing: PosN 1\n",
      "removing: RRAn 1\n",
      "removing: RRAe 1\n",
      "removing: Shed 1\n",
      "removing: Floor 1\n",
      "removing: Po 1\n",
      "Before dropping NA (1441, 28), dropped 7\n"
     ]
    }
   ],
   "source": [
    "def is_unique_value_in_cat_features(data):\n",
    "    ''' This return '''\n",
    "    is_any_unique_value = False\n",
    "    for f in categorical_features:\n",
    "        if (data[f].value_counts() == 1).any():\n",
    "            for i, v in data[f].value_counts().items():\n",
    "                if v == 1:\n",
    "                    print('unique value:', i, v)\n",
    "            is_any_unique_value = True\n",
    "    return is_any_unique_value\n",
    "\n",
    "def remove_unique_value_of_cat_features(data):\n",
    "    before = data.shape[0]\n",
    "    print(f'Before dropping NA {data.shape}')\n",
    "    for f in categorical_features:\n",
    "        if (data[f].value_counts() == 1).any():\n",
    "            remove_list = []\n",
    "            for i, v in data[f].value_counts().items():\n",
    "                if v == 1:\n",
    "                    print('removing:', i, v)\n",
    "                    remove_list.append(i)\n",
    "            data = data[~data[f].isin(remove_list)]\n",
    "    print(f'Before dropping NA {data.shape}, dropped {before - data.shape[0]}')\n",
    "    return data\n",
    "\n",
    "\n",
    "print('is_unique_value_in_cat_features', is_unique_value_in_cat_features(df))\n",
    "df = remove_unique_value_of_cat_features(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Onehot Encoding is being used for categorical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25373/1024340132.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col_name] = (data_to_encode == cat_value) * 1.0\n"
     ]
    }
   ],
   "source": [
    "def encode_onehot(data, column_name):\n",
    "    ''' This onhot encode the categorical columns and drop the original column\n",
    "    \n",
    "    '''  \n",
    "    categorical_values = data[column_name].unique()\n",
    "    data_to_encode = data.pop(column_name)\n",
    "\n",
    "    for cat_value in categorical_values:\n",
    "        col_name = column_name+str(cat_value)\n",
    "        data[col_name] = (data_to_encode == cat_value) * 1.0\n",
    "\n",
    "\n",
    "def encode_cat_features(data, features):\n",
    "    for f in features:\n",
    "        encode_onehot(data, f)\n",
    "\n",
    "\n",
    "encode_cat_features(df, categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1441, 115)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data but since we need further analysis just combine back the Sales Price\n",
    "X_train, X_test, y_train, y_test = data_loader.split_data_df(\n",
    "    df, combine_back=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the correlation of nominal features and drop columns if they are highly correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_highly_corrlated_features(X_train, X_test):\n",
    "    X_train = X_train.drop(['1stFlrSF', '2ndFlrSF'], axis=1)\n",
    "    X_test = X_test.drop(['1stFlrSF', '2ndFlrSF'], axis=1)\n",
    "    # assuming this is final analysis so take out the Sales Proce\n",
    "    y_train = X_train.pop('SalePrice')\n",
    "    y_test = X_test.pop('SalePrice')\n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "X_train, X_test, y_train, y_test = drop_highly_corrlated_features(X_train, X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normilize Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First checking out the stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>...</th>\n",
       "      <th>RoofStyleFlat</th>\n",
       "      <th>HeatingGasA</th>\n",
       "      <th>HeatingGasW</th>\n",
       "      <th>HeatingGrav</th>\n",
       "      <th>HeatingWall</th>\n",
       "      <th>HeatingOthW</th>\n",
       "      <th>HeatingQCEx</th>\n",
       "      <th>HeatingQCGd</th>\n",
       "      <th>HeatingQCTA</th>\n",
       "      <th>HeatingQCFa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1152.000000</td>\n",
       "      <td>1152.000000</td>\n",
       "      <td>1152.000000</td>\n",
       "      <td>1152.000000</td>\n",
       "      <td>1152.000000</td>\n",
       "      <td>1152.000000</td>\n",
       "      <td>1152.000000</td>\n",
       "      <td>1152.000000</td>\n",
       "      <td>1152.000000</td>\n",
       "      <td>1152.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1152.000000</td>\n",
       "      <td>1152.000000</td>\n",
       "      <td>1152.000000</td>\n",
       "      <td>1152.000000</td>\n",
       "      <td>1152.000000</td>\n",
       "      <td>1152.000000</td>\n",
       "      <td>1152.000000</td>\n",
       "      <td>1152.000000</td>\n",
       "      <td>1152.000000</td>\n",
       "      <td>1152.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.598090</td>\n",
       "      <td>1984.900174</td>\n",
       "      <td>99.959201</td>\n",
       "      <td>1970.802083</td>\n",
       "      <td>1.048611</td>\n",
       "      <td>1510.681424</td>\n",
       "      <td>6.085938</td>\n",
       "      <td>2.876736</td>\n",
       "      <td>1042.581597</td>\n",
       "      <td>10342.031250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.004340</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>0.499132</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>0.032118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>39.765308</td>\n",
       "      <td>20.585005</td>\n",
       "      <td>172.030292</td>\n",
       "      <td>30.366955</td>\n",
       "      <td>0.223077</td>\n",
       "      <td>502.691564</td>\n",
       "      <td>1.365611</td>\n",
       "      <td>0.826629</td>\n",
       "      <td>412.395673</td>\n",
       "      <td>9743.305174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088081</td>\n",
       "      <td>0.148591</td>\n",
       "      <td>0.117081</td>\n",
       "      <td>0.065766</td>\n",
       "      <td>0.050987</td>\n",
       "      <td>0.041649</td>\n",
       "      <td>0.500216</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>0.457079</td>\n",
       "      <td>0.176390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>438.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1967.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1125.750000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>791.750000</td>\n",
       "      <td>7500.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1972.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>984.000000</td>\n",
       "      <td>9423.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>164.250000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1779.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1278.000000</td>\n",
       "      <td>11475.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>738.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3627.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3200.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          PoolArea  YearRemodAdd   MasVnrArea    YearBuilt  KitchenAbvGr  \\\n",
       "count  1152.000000   1152.000000  1152.000000  1152.000000   1152.000000   \n",
       "mean      2.598090   1984.900174    99.959201  1970.802083      1.048611   \n",
       "std      39.765308     20.585005   172.030292    30.366955      0.223077   \n",
       "min       0.000000   1950.000000     0.000000  1872.000000      0.000000   \n",
       "25%       0.000000   1967.000000     0.000000  1954.000000      1.000000   \n",
       "50%       0.000000   1993.000000     0.000000  1972.000000      1.000000   \n",
       "75%       0.000000   2004.000000   164.250000  2000.000000      1.000000   \n",
       "max     738.000000   2010.000000  1600.000000  2010.000000      3.000000   \n",
       "\n",
       "         GrLivArea  OverallQual  BedroomAbvGr  TotalBsmtSF        LotArea  \\\n",
       "count  1152.000000  1152.000000   1152.000000  1152.000000    1152.000000   \n",
       "mean   1510.681424     6.085938      2.876736  1042.581597   10342.031250   \n",
       "std     502.691564     1.365611      0.826629   412.395673    9743.305174   \n",
       "min     438.000000     1.000000      0.000000     0.000000    1300.000000   \n",
       "25%    1125.750000     5.000000      2.000000   791.750000    7500.000000   \n",
       "50%    1457.000000     6.000000      3.000000   984.000000    9423.000000   \n",
       "75%    1779.000000     7.000000      3.000000  1278.000000   11475.000000   \n",
       "max    3627.000000    10.000000      8.000000  3200.000000  215245.000000   \n",
       "\n",
       "       ...  RoofStyleFlat  HeatingGasA  HeatingGasW  HeatingGrav  HeatingWall  \\\n",
       "count  ...    1152.000000  1152.000000  1152.000000  1152.000000  1152.000000   \n",
       "mean   ...       0.007812     0.977431     0.013889     0.004340     0.002604   \n",
       "std    ...       0.088081     0.148591     0.117081     0.065766     0.050987   \n",
       "min    ...       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%    ...       0.000000     1.000000     0.000000     0.000000     0.000000   \n",
       "50%    ...       0.000000     1.000000     0.000000     0.000000     0.000000   \n",
       "75%    ...       0.000000     1.000000     0.000000     0.000000     0.000000   \n",
       "max    ...       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "       HeatingOthW  HeatingQCEx  HeatingQCGd  HeatingQCTA  HeatingQCFa  \n",
       "count  1152.000000  1152.000000  1152.000000  1152.000000  1152.000000  \n",
       "mean      0.001736     0.499132     0.171875     0.296875     0.032118  \n",
       "std       0.041649     0.500216     0.377436     0.457079     0.176390  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "75%       0.000000     1.000000     0.000000     1.000000     0.000000  \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  \n",
       "\n",
       "[8 rows x 112 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats():\n",
    "    stats = X_train.describe()\n",
    "    return stats.transpose()\n",
    "\n",
    "def normalize(data, stats):\n",
    "    return (data - stats['mean']) / stats['std']\n",
    "\n",
    "def get_normilze_data():\n",
    "    # using the same stats for both train and test\n",
    "    stats = get_stats()\n",
    "    norm_X_train = normalize(X_train, stats)\n",
    "    norm_X_test = normalize(X_test, stats)\n",
    "    return norm_X_train, norm_X_test\n",
    "\n",
    "\n",
    "norm_X_train, norm_X_test = get_normilze_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1152, 112), (289, 112), 112)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_X_train.shape, norm_X_test.shape, len(norm_X_train.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "If there was problem then some will be Nan because of divided to zero) so vefirying that there is no missing value after normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "norm_X_train.isna().values.any(), norm_X_test.isna().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is not NA value so normilzation was successful"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2ec5ef2ef6915d277aaea50dc172e794b982cc5f41075f1dfd6598edc485a9d8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('w207final': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
