{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_y4okRUhPjC9"
      },
      "source": [
        "# Final Project Baseline: House Prices- Advanced Regression Techniques\n",
        "### Author: Radia Abdul Wahab, Parham Motameni, Jun Qian\n",
        "### Date: Fall 2021\n",
        "### Course: w207 Machine Learning\n",
        "\n",
        "\n",
        "\n",
        "# "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Table of Contents:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hN7Ygmt9PjDB"
      },
      "source": [
        "\n",
        "\n",
        "#### **Project Summary**\n",
        "\n",
        "#### **Description of Data and Data source**\n",
        "\n",
        "#### **Installations and Libraries**\n",
        "\n",
        "#### **Dataset Exploratory Analysis**\n",
        "\n",
        ">Format of Data\n",
        "\n",
        ">Summmary Statistics\n",
        "\n",
        "\n",
        "#### **Step-By-Step performance of algorithms**\n",
        "\n",
        ">...\n",
        "\n",
        ">...\n",
        "\n",
        "\n",
        "\n",
        "#### **Conclusion**\n",
        "#### **Further work for final submission**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Project Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJE3XQpbPjDC"
      },
      "source": [
        "## **Motivation**:\n",
        "How much would you pay for a house? That is often one of the hardest questions to answer. When buying a house or selling a house, it is very crucial to determine the right pricing, since house prices change over time and each house its own \"$ rating\". \n",
        "\n",
        "Three main aspects determine the price of a house. \n",
        "1. Condition\n",
        "2. Features (Number of rooms, square footage etc)\n",
        "3. Location\n",
        "    \n",
        "These 3 properties can be defined under a large set of sub-properties. The **Ames Housing dataset** was compiled by **Dean De Cock**, with 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa. This data set (https://www.kaggle.com/c/house-prices-advanced-regression-techniques) is being used for this project to demonstrate the use of various Machine Learning techniques, to be able to have the algorithm perform the difficult task of deciding what the house price should be. \n",
        "\n",
        " \n",
        "## **Baseline Project Goals**: Through this baseline project we are trying to answer 3 main questions:\n",
        "1. What combination of aspects of a house most determines the sale-price?\n",
        "2. Can Regression based prediction be used to estimate the price of the house?\n",
        "3. What is the best accuracy that can be achieved by using such algorithms?\n",
        "\n",
        "\n",
        "## **Baseline Overall Strategy**: The general strategy we followed to come to the conclusion has been:\n",
        "1. Thorough review of the description of data provided (including background research)\n",
        "2. Reviewing ALL of the variables, in order to avoid omitted variable bias. \n",
        "3. Making a list of ordinal, categorical parameters that seem to be strongly correlated, to be used in decision tree based algorithms for later stages of project including final submission\n",
        "4. EDA of ALL integer based paremeters\n",
        "5. Shortlisting parameters that show strong trends and removing any categorical numerical variables\n",
        "6. Perform Regression using only the shortlisted parameters\n",
        "7. First pass accuracy assessment of basic linear regression without any data cleaning\n",
        "8. Removing outliers, redoing linear regression, recalculating accuracy to show improvement\n",
        "\n",
        "\n",
        "We have answered the above questions stated under \"Baseline Project Goals\" by Exploring the data (EDA) and performing Linear Regression on a selected set of parameters. The outcome is delailed below\n",
        "\n",
        "## **Outcome**:\n",
        "\n",
        "1. The 10 important parameters are: ...\n",
        "2. Linear regression line fit can be obtained\n",
        "3. Accuracy of prediction with a linear regression fit is >80%\n",
        "\n",
        "## **Baseline Submission Content**:\n",
        "For this baseline submission we show an overview of exploratory data analysis (EDA), and demonstrate the data  with sufficient visuals. We then set up a pipeline to demonstrate feasibility of using this data to perform prediction on house prices. \n",
        "\n",
        "In this report we have also included:\n",
        "\n",
        "1. The format of the data\n",
        "2. The various paremeters given\n",
        "3. Distribution of the integer based parameters by visualization\n",
        "4. Descripencies of those parameters and how those will effect us\n",
        "5. Short listed parameters and justification for choice\n",
        "6. Demonstration of a simple regression algorithm to show a regression fit\n",
        "7. Visualizaion of regression line fit \n",
        "8. Visualization of actual vs predicted values to demonstrate fit\n",
        "9. Accuracy estimates\n",
        "10. Summary Statistics?\n",
        "11. Conclusion\n",
        "12. Further work\n",
        "   \n",
        "\n",
        "## **Further work**:\n",
        "Feature engineering and advanced regression techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3zbP1UlPjDD"
      },
      "source": [
        "# Description of Data and Data Source\n",
        "\n",
        "- **Data Source**:\n",
        "\n",
        "- **Description of Data**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "V4u6CpWpPjDD",
        "outputId": "e948e52d-e17e-49d8-9eb6-1630918efe97"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "# New Section Heading:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vNHwnIAsPjDE",
        "outputId": "5463d103-f153-4230-d83b-0500b17c444b"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "\n",
        "from IPython.display import Image, display\n",
        "\n",
        "display(Image(filename='Images/Image1.png'))\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMZoHXWePjDF"
      },
      "source": [
        "# Code Base with outcomes and assesments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Z-1yFvJPjDF"
      },
      "source": [
        "## Import all Libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ncAF-sIOPjDG",
        "outputId": "7db46d42-c6f4-4f7c-cf48-c2d320109079"
      },
      "outputs": [],
      "source": [
        "# This tells matplotlib not to try opening a new window for each plot.\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.pipeline import Pipeline\n",
        "from matplotlib.ticker import MultipleLocator\n",
        "from pathlib import Path\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import random\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import scipy.io as sio\n",
        "\n",
        "%matplotlib inline\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjVSZGLoPjDH",
        "outputId": "bc2b7bd9-5a93-41b1-9172-9e13b0b138ec"
      },
      "outputs": [],
      "source": [
        "# download data file if it is not ready\n",
        "data_path = 'data/train.csv'\n",
        "data_file = Path(data_path)\n",
        "if data_file.is_file():\n",
        "    print(\"Datafile is already loaded.\")\n",
        "else:\n",
        "    !mkdir 'data/'\n",
        "    !curl - L \"https://drive.google.com/uc?export=download&id=1ortEJfmlpt9-dbg5f6cTDt5nicswf5wT\" > 'data/test.csv'\n",
        "    !curl - L \"https://drive.google.com/uc?export=download&id=1EG5jP5RDEIsNAMaF2m42KOyz-ZVjC8wS\" > 'data/train.csv'\n",
        "df = pd.read_csv(data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRNfelLOPjDH"
      },
      "outputs": [],
      "source": [
        "# lock the seed to have repeatable results\n",
        "random.seed(100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7I5yZrSPjDI"
      },
      "source": [
        "## Split training data into our own train and test data:\n",
        "#### The \"test.csv\" is an unlabelled set. Therefore in order to assess performance we are splitting the train.csv into our own training, development and test set as needed\n",
        "#### We are using split() to ensure random distribution of data points\n",
        "#### We are starting off with ~10% of the train set into a test group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JUDtInxPjDI"
      },
      "outputs": [],
      "source": [
        "# Create train, dev, test datasets\n",
        "# for features we do not need Id and we need to remove SalesPrice\n",
        "df_X = df.drop(['SalePrice', 'Id'], axis=1)\n",
        "df_y = df[['SalePrice']].copy()\n",
        "# split data into Test and train\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df_X, df_y, test_size=0.10, random_state=1)\n",
        "\n",
        "# TODO split more to dev set if needed!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "pnj0xm0RPjDI",
        "outputId": "c8f23c5b-00ee-49fe-cc13-3115f64edb48"
      },
      "outputs": [],
      "source": [
        "print(f'X_train size: {X_train.shape}, X_test size: {X_test.shape}')\n",
        "print(type(df))\n",
        "print(type(X_train))\n",
        "X_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xkp5NNh9PjDI"
      },
      "source": [
        "## Initial Look at the data:\n",
        "1.  Our **train** set now is **1314 long** (1314 labelled houses)\n",
        "2.  Our **test** set now is **146 long** (146 labelled houses)\n",
        "3.  Each house has **79 features**. \n",
        "4.  Features are a mix of **nominal, ordinal and categorical**\n",
        "5.  We will have to be cognisant of the different data types for ALL our assessments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "RrU7I9V0PjDJ",
        "outputId": "fd925940-17f0-4f6b-e703-0653ce891c7f"
      },
      "outputs": [],
      "source": [
        "print(f'yy_train size: {y_train.shape}, y_test size: {y_test.shape}')\n",
        "y_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gIWFzT8PjDJ"
      },
      "source": [
        "## Initial Look at the data labels:\n",
        "1. The label set only has one column **Sale Price**\n",
        "2. Indexes match with the train set above\n",
        "3. The train set and test set labels are of same lenght (1314 and 146 respectively)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXkZWr15PjDJ"
      },
      "source": [
        "## Taking a look at what the features are\n",
        "Additionally reviewed the data_description.txt file. The column names and the names on the file correspond accurately"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SX-xo46ePjDJ"
      },
      "source": [
        "# First pass with Nominal values ONLY\n",
        "\n",
        "First lets work on the nominal variables.\n",
        "\n",
        "I would like to see how the data points are distributed, before any data cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0tDIDkGPjDJ"
      },
      "source": [
        "## Analysis on SalePrice\n",
        "\n",
        "#### For SalePrice,  we use the mean price and variation range to determine whether we should seperate the sales price into before and after financial crisis. The observations are:\n",
        "#### We do see a trend change from upward to decrease/flat in price \n",
        "#### However, the difference is only around 5% with a similar variation. As a result, in this stage, we keep it as is for cross sectional analysis. We might look into it further later.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "rBVPNHymPjDK",
        "outputId": "336399a5-5d4d-4030-f456-10509bb61cbe"
      },
      "outputs": [],
      "source": [
        "#try to explore the impact of financial crisis to house prices#\n",
        "df_train=y_train.merge(X_train, how=\"inner\",left_index=True,right_index=True)\n",
        "df_train[['SalePrice','YrSold']].groupby(['YrSold']).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "XWWJCIF1PjDK",
        "outputId": "6140b864-d2dd-4ad9-97a5-81666706c9a3"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(x= df_train['YrSold'], y= df_train['SalePrice'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Qdv_YbEPjDK"
      },
      "source": [
        "## For all the features, check whether there are variables with significant missing values. \n",
        "\n",
        "#### It looks like PoolQC , MiscFeature, Alley, Fence, FireplaceQu have substantial missing values\n",
        "#### However, looking closer into the variables, the NA values just mean there is no such a feature. So we fill it with \"NonExist\" as a different category."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlzcjcwFPjDL",
        "outputId": "77b89d91-3b09-4695-a81c-445331747175"
      },
      "outputs": [],
      "source": [
        "X_train.isnull().sum().sort_values(ascending=False).head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iQq1NdRPjDL",
        "outputId": "18259e25-bcf1-4df3-d354-99945c7e658a"
      },
      "outputs": [],
      "source": [
        "# Check the descrptions and all missing values means the house does not have this feature. To \n",
        "\n",
        "X_train[['PoolQC','MiscFeature','Alley','Fence','FireplaceQu']]=X_train[['PoolQC','MiscFeature','Alley','Fence','FireplaceQu']].fillna('NonExist')\n",
        "X_train.isnull().sum().sort_values(ascending=False).head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJ465FvyPjDL"
      },
      "outputs": [],
      "source": [
        "df_EDA=y_train.merge(X_train, how=\"inner\",left_index=True,right_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA026XoVPjDL"
      },
      "source": [
        "## First step exploratory data analysis:\n",
        "\n",
        "### We classify the features into two types of variables: Numerical and Categorical. \n",
        "\n",
        "### For all the numerical variables, we plot the correlations heatmap between the dependent variable SalePrice and all the features. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3e8qlBzPjDL"
      },
      "outputs": [],
      "source": [
        "## all numeric variables##\n",
        "df_num_list=df_EDA.select_dtypes(exclude={'object'}).columns.to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "X_ihM45YPjDL",
        "outputId": "4f960567-d59d-4f47-a49c-3ebf6d3c0070"
      },
      "outputs": [],
      "source": [
        "corr_matrix = df[df_num_list].corr()\n",
        "\n",
        "fig = plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(corr_matrix)\n",
        "plt.title(\"Correlation heatmap\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "NGlPRfs1PjDM",
        "outputId": "067c6ab5-90e6-4a6b-b940-d3415b0f6eba"
      },
      "outputs": [],
      "source": [
        "##Pick the top 15 correlated features##\n",
        "\n",
        "top15_corr = corr_matrix.sort_values('SalePrice', ascending= False)[0:15]\n",
        "top15_corr = top15_corr.loc[:, top15_corr.index]\n",
        "\n",
        "fig = plt.figure(figsize= (8, 8))\n",
        "sns.heatmap(top15_corr, annot= True)\n",
        "plt.title(\"Top 15 heatmap\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PILCoMxWPjDM"
      },
      "source": [
        "## The correlations heatmap shows:\n",
        "\n",
        "\n",
        "###  1. Below features are highly correlated with SalePrice: \n",
        "\n",
        "- 'OverallQual' \n",
        "- 'GrLivArea' \n",
        "- 'GarageCars' \n",
        "- 'GarageArea' \n",
        "- 'TotalBsmtSF' \n",
        "- '1stFlrSF' \n",
        "- 'FullBath' \n",
        "- 'TotRmsAbvGrd' \n",
        "- 'YearBuilt'\n",
        "- 'YearRemodAdd'  \n",
        "\n",
        "###  2. However, there are high correlations also between features themselves\n",
        "\n",
        "-  OverallQual & most other variables\n",
        "-  GrLivArea & TotRMAbvGrd &  FullBath \n",
        "-  GarageCares & GarageArea\n",
        "-  TotalbsmtSF & 1stFlrSF\n",
        "-  BsmtFinSF1 $ TotBsmtSF\n",
        "\n",
        "## 3. First round for baseline features to include:\n",
        "\n",
        "-  Yearbuilt \n",
        "-  YearRemodAdd \n",
        "-  GrLivArea \n",
        "-  TotalBsmtSF \n",
        "-  GarageCars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mCybaWePjDM"
      },
      "outputs": [],
      "source": [
        "#all text variable (categorical)#\n",
        "df_txt_list=df_EDA.select_dtypes(include={'object'}).columns.to_list()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgBn3bKfPjDM"
      },
      "source": [
        "### For all the categorical variables, we plot the box plots to see whether any category in the variable has a significant different SalePrice. We conclude as below:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "LdEWA4AaPjDP",
        "outputId": "5c6b0f1e-573f-4717-fbc0-6dfaecefca8a"
      },
      "outputs": [],
      "source": [
        "df[df_txt_list].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0htXOXOxPjDP",
        "outputId": "5258301f-1747-4469-b6ff-b3b46560732b",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "df[df_txt_list].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "dUltZNv_PjDQ",
        "outputId": "229a105f-ef70-42f3-d06c-f76d7157d890"
      },
      "outputs": [],
      "source": [
        "#box plot to explore categorical variables\n",
        "\n",
        "n_rows=15\n",
        "n_cols=3\n",
        "\n",
        "fig, axs = plt.subplots(n_rows, n_cols, figsize= (4*n_cols, 3*n_rows))\n",
        "\n",
        "for row in range(n_rows):\n",
        "    for col in range(n_cols):\n",
        "        i = row * 3 + col\n",
        "        if i >= len(df_txt_list):\n",
        "            break\n",
        "        variable = df_txt_list[i]\n",
        "        sns.boxplot(x= df[variable], y= df['SalePrice'], ax= axs[row, col])\n",
        "        \n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqGu8jx4PjDQ"
      },
      "source": [
        "### For all the categorical variables, we plot the box plots to see whether any category in the variable has a significant different SalePrice. We conclude as below:\n",
        "\n",
        "####  1. Below features are highly correlated with SalePrice: \n",
        "\n",
        "\n",
        "- The features related to location:\n",
        "\n",
        "    1. Neighborhood: some neighborhoods have significant higher mean price.\n",
        "    2. MSZoning: FV(Floating Village(FV) is a special area where a retirement community was developed and have a higher mean price. Commercial has low mean price. \n",
        "    3. Condition1/Condition2: if there are positive off-site facilities, the prices of properties are higher.\n",
        "\n",
        "\n",
        "- Generally all \"quality\" features, when the quality is excellent or good, the prices is significantly higher.\n",
        "\n",
        "    4. BsmtQual\n",
        "    5. KitchenQual\n",
        "    6. exterCond\n",
        "    7. PoolQC\n",
        "\n",
        "\n",
        "- Features related to the house:\n",
        "\n",
        "\n",
        "    8. MasVnrType: Stone Veneer is higher. \n",
        "    9. GarageType:  BuiltIn is meaningfully higher\n",
        "\n",
        "\n",
        "####  2. However, there are high correlations also between features themselves:\n",
        "\n",
        "Such as all quality features, the quality with whether the house has heating and central air\n",
        "\n",
        "#### 3. Some features we will further explore: \n",
        "\n",
        "    1. LandContour\n",
        "    2. BldgType:  TwnhsE/TwnhsI  might have info but not obvious\n",
        "    3. HouseStyle: has info but might be correlated with house sqft\n",
        "    4. RoofMati: has significant difference in values but might also add noises\n",
        "    5. 'ExterQual'/ 'ExterCond': check correlation with other quality\n",
        "    6. BsmtExposure: Gd(good exposure) or No has significant differences in price. check correlation with BsmtQual\n",
        "    7. BsmtFinType1:\n",
        "    8. Exterior1st&2nd\n",
        "    9. functional\n",
        "    10. saletype: new construction is higher but correlated? with yr built\n",
        "    11. SaleCondition'\n",
        "    12. FireplaceQu\n",
        "    13. Heating\n",
        "    14. Central Air\n",
        "    4. HeatingQual\n",
        "    5. garageQual\n",
        "#### 4. Below features we are not planning to include:\n",
        " 'Street',\n",
        " 'Alley',\n",
        " 'LotShape',,\n",
        " 'Utilities'\n",
        " 'LotConfig',\n",
        " 'LandSlope',\n",
        " 'RoofStyle',\n",
        " 'Exterior1st',\n",
        " 'Exterior2nd',\n",
        " 'Foundation',\n",
        " 'BsmtCond',\n",
        " 'BsmtFinType1',\n",
        " 'BsmtFinType2',\n",
        " 'Electrical',\n",
        " 'GarageFinish',\n",
        " 'GarageCond',\n",
        " 'PavedDrive',\n",
        " 'Fence',\n",
        " 'MiscFeature'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTrdBKMlPjDQ"
      },
      "source": [
        "## Plotting all the nominal values to take a look at the data distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4GUknAnSiP7"
      },
      "outputs": [],
      "source": [
        "#isolating all nominal value formats\n",
        "#Using a list of python var types to filter through all the columns\n",
        "#Initial nominal value list is \"int_feature_list\"\n",
        "\n",
        "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "\n",
        "nominal_df = X_train.select_dtypes(include=numerics)\n",
        "\n",
        "int_feature_list = nominal_df.columns.values.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qOvfWLbhPjDQ",
        "outputId": "ff15b7ed-48d5-4f8c-fec0-177be1851a82"
      },
      "outputs": [],
      "source": [
        "# Using the shortlisted feature list, run a for loop to plot all the data points\n",
        "# int_feature_list has been created a few cells above\n",
        "# int_feature_list contains all the columns that have some sort of numbers in them (int, float etc)\n",
        "\n",
        "k=1\n",
        "plt.figure(figsize=(30,30)) #Using a large figsize to make it easy to visualize everything\n",
        "\n",
        "for feature in int_feature_list: \n",
        "    \"\"\" Looping through the int_feature_list\n",
        "        plotting each of the columns from the train matrix on the horizontal axis\n",
        "        against SalePrice (data labels) on the vertical axis\n",
        "        in order to \"view\" any obvious correlation or non-correlation\n",
        "    \"\"\"\n",
        "    output= ['SalePrice']\n",
        "    plt.subplot(6, 6, k)\n",
        "    plt.scatter(X_train[feature].values, y_train[output].values);\n",
        "    plt.xlabel(feature)\n",
        "    plt.ylabel('Sale Price')\n",
        "    plt.yticks([])\n",
        "    k=k+1\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# For each integer parameter make a first off decision on what needs to be done with that parameter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjnhYj-ePjDR"
      },
      "source": [
        "## \n",
        "\n",
        "### In this section we review ALL the variables. \n",
        "### We look at each plot above, as well as the description provided to us in data_description.txt\n",
        "### We \"plan ahead\" what we could potentially do with each variable/feature\n",
        "### However, we will not be including ALL of these features in our baseline evaluation\n",
        "## \n",
        "\n",
        "1. **MSSubClass**: Identifies the type of dwelling involved in the sale.\n",
        "\n",
        "Need to convert this to categorical, or ordinal. For Baseline we will not be using this. In terms of conversion to ordinal, this is not ordered currently. We will need to identify what criteria should be used to order these. However, this variable determines the type of property and is ultimately a critical feature that needs to be captured in the final ML algorithm.\n",
        "\n",
        "2. **LotFrontage**: Linear feet of street connected to property\n",
        "\n",
        "Need to remove values above 200. They are clearly outliers that are skewing the data on the right\n",
        "\n",
        "Once we remove the outliers, we should see a good correlation, visually\n",
        "\n",
        "3. **LotArea**: Lot size in square feet\n",
        "\n",
        "This is an important parameter\n",
        "\n",
        "However, looking at the scatter plot, I would say there are a few outliers that significantly skew the data\n",
        "\n",
        "we should remove any values that are >50K and perform our final analysis.\n",
        "\n",
        "Once we remove the outliers above 50k, we should get a reasonable correlation\n",
        "\n",
        "4. **OverallQual**: Rates the overall material and finish of the house\n",
        "\n",
        "Similar to the MSSubClass, this is actually a ordinal variable with a numerical rating. \n",
        "\n",
        "From the description.txt, it seems like it is ordered in the right way. \n",
        "\n",
        "5. **OverallCond**: Rates the overall condition of the house\n",
        "\n",
        "Same feedback as OverallQual\n",
        "\n",
        "6. **YearBuilt**: Original construction date\n",
        "\n",
        "Can be used as-is for now. Keeping in mind, this is a time variable\n",
        "\n",
        "7. **YearRemodAdd**: Remodel date (same as construction date if no remodeling or additions)\n",
        "\n",
        "This is a tricky parameter. we need to figure out what to do with the data points where the house was not remodeled but is copying the construction date\n",
        "\n",
        "Looking at the scatter plot, rest of the data points seem good. My only concern is the piling up of data on 1950\n",
        "\n",
        "Also need to keep in mind this is a time variable\n",
        "\n",
        "8. **MasVnrArea**: Masonry veneer area in square feet\n",
        "Need to remove zero value \n",
        "\n",
        "Asses with  vs without Masonry veneer (consider using as binary variable in the final ML)\n",
        "Then if with Masonry veneer, perform correlation assessment. \n",
        "\n",
        "9. **BsmtFinSF1**: Type 1 finished square feet\n",
        "Need to remove zero values\n",
        "\n",
        "Asses with basement vs without (consider using binary assessment)\n",
        "Then if with basement, need to remove '0' values and perform correlation\n",
        "\n",
        "10. **BsmtFinSF1**: Type 1 finished square feet, **BsmtFinSF2**: Type 2 finished square feet, **BsmtUnfSF**: Unfinished square feet of basement area. **TotalBsmtSF**: Total square feet of basement area\n",
        "\n",
        "Remove zeros\n",
        "Identify creative ways to combine these variables into one, and use some form of a rating to convert into ordinal to perform assessment. Or use decision tree.\n",
        "\n",
        "11. **1stFlrSF**: First Floor square feet, **2ndFlrSF**: Second floor square feet\n",
        "\n",
        "Perform assessment on total square feet.\n",
        "\n",
        "For second floor square feet, remove the zero values\n",
        "\n",
        "12. **LowQualFinSF**: Low quality finished square feet (all floors)\n",
        "\n",
        "This to me should be a binary classifier. There is a vertical line on zero, and all other data points can be represented with almost a horizontal line\n",
        "\n",
        "13. **GrLivArea**: Above grade (ground) living area square feet\n",
        "\n",
        "Destribution of data point is almost identical to 1stFlrSF. This is not a suprise. I don't think we should include this variable. This will diminish the effects of the original variable (1stFlrSF or overall SF)\n",
        "\n",
        "14. **BsmtFullBath**: Basement full bathrooms, **BsmtHalfBath**: Basement half bathrooms, **FullBath**: Full bathrooms above grade, **HalfBath**: Half baths above grade\n",
        "\n",
        "All bathroom formats should be combined into a ordinal format. Need to figure out how. we could do it based on mean. The higher the mean sale price, higher the ordinal value.\n",
        "\n",
        "15. **Bedroom**: Bedrooms above grade (does NOT include basement bedrooms), **TotRmsAbvGrd**: Total rooms above grade (does not include bathrooms)\n",
        "\n",
        "Traditionally, this is a huge contributing factor. Lets see how we can capture this\n",
        "\n",
        "Need to combine Bedrooms and total room somehow\n",
        "\n",
        "Decision tree might be a good option for this\n",
        "\n",
        "16. **Kitchen**: Kitchens above grade\n",
        "\n",
        "Very interesting distribution. seems to be a negative correlation\n",
        "\n",
        "17. **Fireplaces**: Number of fireplaces\n",
        "\n",
        "I think we can deprioritize this variable for now, but include in final ML\n",
        "\n",
        "18. **GarageYrBlt**: Year garage was built\n",
        "\n",
        "This is an important variable. Can use as is. But need to remove zeroes\n",
        "\n",
        "19. **GarageCars**: Size of garage in car capacity\n",
        "\n",
        "important variable. looks like good correlation\n",
        "\n",
        "20. **GarageArea**: Size of garage in square feet\n",
        "\n",
        "Good variable. Need to remove zeroes\n",
        "\n",
        "21. **WoodDeckSF**: Wood deck area in square feet, **OpenPorchSF**: Open porch area in square feet, **EnclosedPorch**: Enclosed porch area in square feet, **3SsnPorch**: Three season porch area in square feet, **ScreenPorch**: Screen porch area in square feet, **PoolArea**: Pool area in square feet\n",
        "\n",
        "These can be combined into some \"additional amenities\". can keep the sqft measure. need to decide\n",
        "\n",
        "In any case, need to remove zeroes. \n",
        "\n",
        "22. **MiscVal**: $Value of miscellaneous feature\n",
        "\n",
        "Need to figure out how we can include this. I dont think we can add the value to the total. because value of misc features might actually hold lesser real value.\n",
        "\n",
        "will deprioritize this for now and think about it. \n",
        "\n",
        "23. **MoSold**: Month Sold (MM), **YrSold**: Year Sold (YYYY):\n",
        "\n",
        "Effects of year seems to be negligible... maybe because it is over a very short duration. Month to Month variability is more significant\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_hSgKEwPjDR"
      },
      "source": [
        "## From the above assessment it is clear that we might need to heavily depend on learning algorithms that are designed for categorical data as well as nominal data\n",
        "\n",
        "### At this point we will make two lists of \"Important Variables\" from either category, so we can perform an initial baseline assessment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# In this section, we prioritize which Nominal/Ordinal Variables to work on for baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsfFExUbPjDR"
      },
      "source": [
        "\n",
        "\n",
        "1. LotFrontage\n",
        "2. LotArea\n",
        "3. OverallQual\n",
        "4. OverallCond\n",
        "5. Yearbuilt\n",
        "6. YearRemodAdd\n",
        "7. GrLivArea\n",
        "8. Bathroom (Need to sum all the types)\n",
        "9. GarageYrBlt\n",
        "10. GarageCars\n",
        "11. GarageArea"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# In this section, we prioritize which Categorical Variables to work on for baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFUnpncoPjDR"
      },
      "source": [
        "\n",
        "1. MoSold\n",
        "2. MSZoning\n",
        "3. BldgType\n",
        "4. HouseStyle\n",
        "5. ExterCond (Convert to Ord)\n",
        "6. Foundation\n",
        "7. BsmtFinType1 (Convert to Ord)\n",
        "8. Heating\n",
        "9. CentralAir (Convert to Binary)\n",
        "10. KitchenQual\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSjSkc_TPjDR"
      },
      "source": [
        "## Shrinking the DataFrame to only include the selected variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "h_SQx79UPjDR",
        "outputId": "3b9585d6-beba-4dc8-874e-2f242b47f2ae"
      },
      "outputs": [],
      "source": [
        "X_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "9dgiWgQQPjDR",
        "outputId": "51339e92-d127-4489-c579-220ee32bcc55"
      },
      "outputs": [],
      "source": [
        "#Selected dataframe\n",
        "\n",
        "selected_X_train = X_train[[\"LotFrontage\",\"LotArea\",\"OverallQual\",\"OverallCond\",\"YearBuilt\",\"YearRemodAdd\",\"GrLivArea\",\"GarageYrBlt\",\"GarageCars\",\"GarageArea\"]]\n",
        "selected_X_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f_QnseJPjDS",
        "outputId": "8171dbcd-703d-4b00-ede6-e18a20197000"
      },
      "outputs": [],
      "source": [
        "#Convert selected dataframe into a numpy array for subsequent calculations\n",
        "\n",
        "selected_array_train=selected_X_train.to_numpy()\n",
        "\n",
        "#Check to see if it worked\n",
        "print(type(selected_X_train))\n",
        "print(type(selected_array_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtOSXctXPjDS",
        "outputId": "06555ed1-9013-4d2d-d9b5-8154bde29278"
      },
      "outputs": [],
      "source": [
        "#Remove NaN values from train array\n",
        "#Check the data in the array\n",
        "\n",
        "selected_array_train[0]\n",
        "selected_array_train[0:5]\n",
        "\n",
        "selected_array_train = np.nan_to_num(selected_array_train, neginf=0) #Removing Nan from train array\n",
        "print(selected_array_train[0:5])\n",
        "#looks like my array works"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxjumCzPPjDS",
        "outputId": "893e96a0-0d0e-47b5-dbc3-ac18432b8782"
      },
      "outputs": [],
      "source": [
        "#Convert selected test dataframe into a numpy array for subsequent calculations\n",
        "#Remove NaN values from test array\n",
        "#Check the data in the array\n",
        "\n",
        "selected_X_test = X_test[[\"LotFrontage\",\"LotArea\",\"OverallQual\",\"OverallCond\",\"YearBuilt\",\"YearRemodAdd\",\"GrLivArea\",\"GarageYrBlt\",\"GarageCars\",\"GarageArea\"]]\n",
        "\n",
        "selected_array_test=selected_X_test.to_numpy()\n",
        "\n",
        "selected_array_test = np.nan_to_num(selected_array_test, neginf=0) #Removing Nan from test array\n",
        "\n",
        "print(selected_array_test[0:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "3utwGwzgPjDS",
        "outputId": "4940b69f-2186-41b5-9796-6a7379ab4dc3"
      },
      "outputs": [],
      "source": [
        "#Re-review the data point distribution of the variables we selected for initial linear regression\n",
        "\n",
        "print('\\033[1m' + 'Data point distribution of the variables we selected for initial Linear Regression' + '\\033[0m')\n",
        "\n",
        "int_feature_list2=[\"LotFrontage\",\"LotArea\",\"OverallQual\",\"OverallCond\",\"YearBuilt\",\"YearRemodAdd\",\"GrLivArea\",\"GarageYrBlt\",\"GarageCars\",\"GarageArea\"]\n",
        "k=1\n",
        "plt.figure(figsize=(30,10))\n",
        "\n",
        "for feature in int_feature_list2:\n",
        "    output= ['SalePrice']\n",
        "    plt.subplot(2, 5, k)\n",
        "    plt.yticks([])\n",
        "    plt.xlabel(feature)\n",
        "    plt.ylabel('Sale Price')\n",
        "    plt.scatter(X_train[feature].values, y_train[output].values)\n",
        "\n",
        "    k=k+1\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 691
        },
        "id": "o3Ww_E3gPjDS",
        "outputId": "183d2b9b-6cb9-4b21-9cd7-56f1d00ca2e4",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "print('\\033[1m' + 'Corresponding Data point distribution of the variables on the test selected for initial Linear Regression' + '\\033[0m')\n",
        "print(\"\")\n",
        "print(\"This is to make sure the test set is not significantly different from the train set.\")\n",
        "print(\"We are cautious to not cheat at this step. But if we see any significant anomaly,\")\n",
        "print(\"we would go back and fix the split train/test\")\n",
        "\n",
        "\n",
        "int_feature_list2=[\"LotFrontage\",\"LotArea\",\"OverallQual\",\"OverallCond\",\"YearBuilt\",\"YearRemodAdd\",\"GrLivArea\",\"GarageYrBlt\",\"GarageCars\",\"GarageArea\"]\n",
        "k=1\n",
        "plt.figure(figsize=(30,10))\n",
        "\n",
        "for feature in int_feature_list2:\n",
        "    output= ['SalePrice']\n",
        "    plt.subplot(2, 5, k)\n",
        "    plt.yticks([])\n",
        "    plt.xlabel(feature)\n",
        "    plt.ylabel('Sale Price')\n",
        "    plt.scatter(X_test[feature].values, y_test[output].values)\n",
        "    k=k+1\n",
        "    \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#  PM Exploratory Version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for features we do not need Id and we need to remove SalesPrice since\n",
        "# #  it is our dependant variable\n",
        "df_X = df.drop(['SalePrice', 'Id'], axis=1)\n",
        "df_y = df[['SalePrice']].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fixup some features (post and pre split)\n",
        "Some of these are post-split but need to redo for test dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analyzing bathroom features impact on house price\n",
        "Here we analyze the relation between the number of bathrooms and the sales price. There are four features in the dataset presenting the bathrooms, full and half bathrooms for both basements and above the ground. Here we analyze each of the features individually and then in combined form. To combine them, we verify two approaches, one considering each half-bath as .5 of a full-bath, and for the other one, we consider each bath as one no matter if it is full or half."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_bath_features_dataset(consider_half_as_full, dataset):\n",
        "    # Set half-bath to half of its value\n",
        "    bath_props = ['BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath']\n",
        "    bath_dataset = dataset[['BsmtFullBath',\n",
        "                        'BsmtHalfBath', 'FullBath', 'HalfBath']].copy()\n",
        "    if not consider_half_as_full:\n",
        "        # Total number of bath = number of full + (number of half/2)\n",
        "        bath_dataset[['BsmtHalfBath', 'HalfBath']] = bath_dataset[[\n",
        "            'BsmtHalfBath', 'HalfBath']].apply(lambda x: x/2, axis=1)\n",
        "    bath_dataset['total_bath'] = bath_dataset[bath_props].apply(np.sum, axis=1)\n",
        "    return bath_dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_features(feature_set, output_set, feature_per_row=2):\n",
        "    plt.figure(figsize=(15, 20))\n",
        "    number_features = len(feature_set)\n",
        "    num_row = number_features // feature_per_row\n",
        "    num_row = num_row if number_features % feature_per_row != 0 else num_row + 1\n",
        "\n",
        "    k = 1\n",
        "    for feature in feature_set:\n",
        "        output = ['SalePrice']\n",
        "        plt.subplot(num_row, feature_per_row, k)\n",
        "        plt.yticks([])\n",
        "        plt.xlabel(feature)\n",
        "        plt.ylabel('Sale Price')\n",
        "        plt.scatter(feature_set[feature].values, output_set[output].values)\n",
        "        k = k+1\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_features(feature_set, output_set, feature_per_row=2,\n",
        "    width=15, height=20):\n",
        "    plt.figure(figsize=(width, height))\n",
        "    number_features = feature_set.shape[1]\n",
        "    num_rows = number_features // feature_per_row\n",
        "    num_rows = num_rows if number_features % feature_per_row == 0 \\\n",
        "         else num_rows + 1\n",
        "    k = 1\n",
        "    for feature in feature_set:\n",
        "        output = ['SalePrice']\n",
        "        plt.subplot(num_rows, feature_per_row, k)\n",
        "        plt.yticks([])\n",
        "        plt.xlabel(feature)\n",
        "        plt.ylabel('Sale Price')\n",
        "        plt.scatter(feature_set[feature].values, output_set[output].values)\n",
        "        k = k+1\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# bathrooms impact on price\n",
        "# TODO probably better to use the train_set instead full set\n",
        "def analyze_num_bath_impact(dataset):\n",
        "    f_baths = get_bath_features_dataset(\n",
        "        consider_half_as_full=True, dataset=dataset)\n",
        "    plot_features(f_baths, df_y[output], feature_per_row=5, height=3)\n",
        "    f_baths = get_bath_features_dataset(\n",
        "        consider_half_as_full=False, dataset=dataset)\n",
        "    plot_features(f_baths, df_y[output], feature_per_row=5, height=3)\n",
        "\n",
        "analyze_num_bath_impact(df_X)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Number of the bathrooms analysis result**\n",
        "The number of bathroom analysis shows that using the total number of bathrooms considering half-bath as half reveals more granular details about the relation between the number of bathrooms with the sales price better than other approaches."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Age of house at sale time, remodlled age at sale time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Selecting a set of feature to work on (THIS IS POST BASIC ANALYSIS STEP)\n",
        "These features are selected based on analysis and impact of them on the price\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_featues():\n",
        "    # we showed that not considering half-bath as full has better revealing factor\n",
        "    f_baths = get_bath_features_dataset(consider_half_as_full=False)\n",
        "    df_X['total_bath'] = f_baths['total_bath']\n",
        "    # Age of house at sale time, remodlled age at sale time\n",
        "    df_X['Age'] = df_X['YrSold'] - df_X['YearBuilt']\n",
        "    df_X['RemodAge'] = df_X['YrSold'] - df_X['YearRemodAdd']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_features():\n",
        "    list_of_features = ['MSSubClass', 'MSZoning', 'LotArea', 'Utilities',\n",
        "                        'Neighborhood', 'OverallQual', 'Age', 'RemodAge',\n",
        "                        'TotRmsAbvGrd', 'KitchenQual', 'YrSold', 'MoSold', 'GrLivArea', 'total_bath']\n",
        "    return df_X[list_of_features].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "build_featues()\n",
        "extract_features()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Encoding Categorical Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def encoding_features():\n",
        "    working_set = extract_features()\n",
        "    index_of_encoded_cols = [working_set.columns.get_loc(col) for col in [\n",
        "        'MSSubClass', 'MSZoning', 'Utilities', 'Neighborhood',  'KitchenQual']]\n",
        "    ct = ColumnTransformer(transformers=[(\n",
        "        'encoder', OneHotEncoder(), index_of_encoded_cols)], remainder='passthrough')\n",
        "    return ct.fit_transform(working_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split data into test and train sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_data(working_set):\n",
        "    return train_test_split(\n",
        "        working_set, df_y, test_size=0.10, random_state=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Add Feature Scaling (POST-SPLIT pre-process)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Save the cleaned data\n",
        "Here we store the cleaned data to just reload them to be used in the models and use it instead of going over the whole wrangling process everytime during the investigation.\n",
        " \n",
        "**The save step should be removed for FINAL just keep the cleaing/encoding part.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_encode_and_save_data():\n",
        "    encoded_feaures = encoding_features()\n",
        "    X_train, X_test, y_train, y_test = split_data(encoded_feaures)\n",
        "    # the save part could be removed for final\n",
        "    sio.mmwrite(\"X_train.mtx\", X_train)\n",
        "    pd.DataFrame(X_test.todense()).to_csv('X_test.csv', index=False)\n",
        "    y_train.to_csv('y_train.csv', index=False)\n",
        "    y_test.to_csv('y_test.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean_encode_and_save_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Start of the Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f35poA0kPjDT",
        "outputId": "3dcac80e-7a63-43da-8e2b-b197998d9573"
      },
      "outputs": [],
      "source": [
        "# model fit\n",
        "lm = LinearRegression(fit_intercept = True)\n",
        "lm.fit(selected_array_train, y_train.values.ravel())\n",
        "lm_yhat = lm.predict(selected_array_test)\n",
        "#print(lm.intercept_)\n",
        "#print(lm.coef_)\n",
        "print ('Estimated function: y = %.2f + %.2fx' %(lm.intercept_, lm.coef_[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "8xDk_yE6PjDT",
        "outputId": "933e8e4f-c635-41b6-f58d-38b4e60833b5"
      },
      "outputs": [],
      "source": [
        "#plot y_test and y_predict to make sure everything looks good visually and is not completely off\n",
        "\n",
        "plt.scatter(y_test,lm_yhat)\n",
        "\n",
        "plt.xlabel(\"y_test\")\n",
        "plt.ylabel(\"y_predict\")\n",
        "plt.xlim(0,600000)\n",
        "plt.ylim(0,600000)\n",
        "\n",
        "lm1 = LinearRegression(fit_intercept = True)\n",
        "lm1.fit(y_test,lm_yhat)\n",
        "print ('Estimated function: y = %.2f + %.2fx' %(lm1.intercept_, lm1.coef_[0]))\n",
        "\n",
        "x=np.linspace(0, 600000)\n",
        "y=39564.48 + 0.77*x\n",
        "plt.plot(x,y)\n",
        "\n",
        "#plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTwsZ89HPjDU"
      },
      "source": [
        "# Furtherwork"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2lA9ji5PjDU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "jgBn3bKfPjDM",
        "UqGu8jx4PjDQ"
      ],
      "name": "w207_Final_Baseline.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "e60adb67eb80270c05ee6b033ce8b930b3ae8adb47b2f7aaebb32759a2596efe"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
