{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Baseline: House Prices- Advanced Regression Techniques\n",
    "### Author: Radia Abdul Wahab, Parham Motameni, Jun Qian\n",
    "### Date: Fall 2021\n",
    "### Course: w207 Machine Learning\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supplementary Notebook for Various Linear Regression Models, Hyperparameter tuning and RMSE assessment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor as DTR\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "\n",
    "# internal modules\n",
    "from base_regressor_plot import BaseRegressorPlot\n",
    "from configurations import args\n",
    "from data_loader import DataLoader\n",
    "from elastic_net_regressor import ElasticNetRegressor\n",
    "from decision_tree_regressor import DecisionTreeRegressor\n",
    "from lasso_regressor import LassoRegressor\n",
    "from linear_regressor import LinearRegressor\n",
    "from random_forest_regressor import RandomForestRegressor\n",
    "from ridge_regressor import RidgeRegressor\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data file if it is not ready\n",
    "data_file = Path(args.data_path)\n",
    "if data_file.is_file():\n",
    "    print(\"Datafile is already loaded.\")\n",
    "else:\n",
    "    !curl -L \"https://drive.google.com/uc?export=download&id=1ortEJfmlpt9-dbg5f6cTDt5nicswf5wT\" > 'test.csv'\n",
    "    !curl -L \"https://drive.google.com/uc?export=download&id=1EG5jP5RDEIsNAMaF2m42KOyz-ZVjC8wS\" > 'train.csv'\n",
    "data_loader = DataLoader(args)\n",
    "df = data_loader.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lock the seed to have repeatable results\n",
    "random.seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into Test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data_loader.df_X, data_loader.df_y, test_size= 0.10, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating Different Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are training multiple regression models on the Training set and at the end we compare the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Regressor \n",
    "Using this as the base class for all regressor to share the common diagnostics like: Plotting RMSE, and other diagnostics plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.list_of_sections_to_skip=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_Scores=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_linear_regression():\n",
    "    X_train, X_test, y_train, y_test = data_loader.get_clean_encoded_data()\n",
    "    regressor = LinearRegressor()\n",
    "    regressor.fit(X_train, y_train)\n",
    "    predicted = regressor.get_predicted(X_test)\n",
    "\n",
    "    \n",
    "    # plot dignostics\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 8))\n",
    "    BaseRegressorPlot.plot_predicted_vs_actual(axes[0], predicted, y_test)\n",
    "    BaseRegressorPlot.plot_learning_curves(axes[1], regressor, data_loader)\n",
    "    print(\"RMSE:\" + str(mean_squared_error(y_test, predicted, squared=False)))\n",
    "    RMSE=mean_squared_error(y_test, predicted, squared=False)\n",
    "    RMSE_Scores.append(RMSE)\n",
    "\n",
    "analyze_linear_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularized Regressions\n",
    "- Rigde Regression\n",
    "- Lasso Regression\n",
    "- Elstic Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression\n",
    "In this section we analyze Ridge regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge is regularized version of linear regression\n",
    "\n",
    "It adds $ \\Sigma_{\\ i=1}^{\\ n} \\ \\theta_i^{\\ 2}$  regularization term to cost function to keep the model weight as samll as possible.\n",
    "\n",
    "Ridge Regression cost function:\n",
    "\n",
    "$$ J(\\theta) \\ = \\ MSE(\\theta) + \\alpha \\ \\frac{1}{2} \\Sigma_{\\ i=1}^{\\ n} \\ \\theta_i^{\\ 2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_ridge_regression():\n",
    "    X_train, X_test, y_train, y_test = data_loader.get_clean_encoded_data()\n",
    "    regressor = RidgeRegressor()\n",
    "    regressor.fit(X_train, y_train)\n",
    "    predicted = regressor.get_predicted(X_test)\n",
    "\n",
    "    \n",
    "    # plot dignostics\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    BaseRegressorPlot.plot_predicted_vs_actual(axes[0], predicted, y_test)\n",
    "    BaseRegressorPlot.plot_learning_curves(axes[1], regressor, data_loader)\n",
    "    print(mean_squared_error(y_test, predicted,squared=False))\n",
    "    RMSE=mean_squared_error(y_test, predicted, squared=False)\n",
    "    RMSE_Scores.append(RMSE)\n",
    "\n",
    "analyze_ridge_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso adds a regularization term to the cost function, but it uses the ℓ1 norm of the weight vector instead of half the square of the ℓ2 norm\n",
    "\n",
    "Lasso Regression cost function\n",
    "\n",
    " $$ J(\\theta) \\ = \\ MSE(\\theta) + \\alpha \\  \\Sigma_{\\ i=1}^{\\ n} \\ |\\theta_i| $$\n",
    "\n",
    "An important characteristic of Lasso Regression is that it tends to eliminate the weights of the least important features (i.e., set them to zero).\n",
    "\n",
    "In other words, Lasso Regression automatically performs feature selection and outputs a sparse model (i.e., with few nonzero feature weights).\n",
    "\n",
    "Note: Lasso regression has $\\alpha$ as hyperparmeter which needs to be searched "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_lasso_regression():\n",
    "    X_train, X_test, y_train, y_test = data_loader.get_clean_encoded_data()\n",
    "    regressor = LassoRegressor(alpha=10)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    predicted = regressor.get_predicted(X_test)\n",
    "\n",
    "    # plot dignostics\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    BaseRegressorPlot.plot_predicted_vs_actual(axes[0], predicted, y_test)\n",
    "    BaseRegressorPlot.plot_learning_curves(axes[1], regressor, data_loader)\n",
    "    #plt.scatter(y_test, regressor.predict(X_test))\n",
    "    print(mean_squared_error(y_test, predicted, squared=False))\n",
    "    RMSE=mean_squared_error(y_test, predicted, squared=False)\n",
    "    RMSE_Scores.append(RMSE)\n",
    "\n",
    "analyze_lasso_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Elastic Net regularization term is a simple mix of both Ridge and Lasso’s regularization terms, and you can control the mix ratio r. When r = 0, Elastic Net is equivalent to Ridge Regression, and when r = 1, it is equivalent to Lasso Regression\n",
    "\n",
    "Elastic Net cost function\n",
    "\n",
    "$$ J(\\theta) \\ = \\ MSE(\\theta) + r \\alpha \\  \\Sigma_{\\ i=1}^{\\ n} \\ |\\theta_i| +  \\frac{1-r}{2} \\alpha \\ \\Sigma_{\\ i=1}^{\\ n} \\ \\theta_i^{\\ 2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_elasticnet_regression():\n",
    "    X_train, X_test, y_train, y_test = data_loader.get_clean_encoded_data()\n",
    "    regressor = ElasticNetRegressor(alpha=0.1, l1_ratio=0.5)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    predicted = regressor.get_predicted(X_test)\n",
    "\n",
    "    # plot dignostics\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    BaseRegressorPlot.plot_predicted_vs_actual(axes[0], predicted, y_test)\n",
    "    BaseRegressorPlot.plot_learning_curves(axes[1], regressor, data_loader)\n",
    "    #plt.scatter(y_test, regressor.predict(X_test))\n",
    "    print(mean_squared_error(y_test, predicted, squared=False))\n",
    "    RMSE=mean_squared_error(y_test, predicted, squared=False)\n",
    "    RMSE_Scores.append(RMSE)\n",
    "\n",
    "analyze_elasticnet_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_decision_tree_regression():\n",
    "    X_train, X_test, y_train, y_test = data_loader.get_clean_encoded_data()\n",
    "    regressor = DecisionTreeRegressor()\n",
    "    regressor.fit(X_train, y_train)\n",
    "    predicted = regressor.get_predicted(X_test)\n",
    "\n",
    "    # plot dignostics\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    BaseRegressorPlot.plot_predicted_vs_actual(axes[0], predicted, y_test)\n",
    "    BaseRegressorPlot.plot_learning_curves(axes[1], regressor, data_loader)\n",
    "    #plt.scatter(y_test, regressor.predict(X_test))\n",
    "    print(mean_squared_error(y_test, predicted, squared=False))\n",
    "    RMSE=mean_squared_error(y_test, predicted, squared=False)\n",
    "    RMSE_Scores.append(RMSE)\n",
    "\n",
    "\n",
    "analyze_decision_tree_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_random_forest_regression():\n",
    "    X_train, X_test, y_train, y_test = data_loader.get_clean_encoded_data()\n",
    "    regressor = RandomForestRegressor()\n",
    "    regressor.fit(X_train, y_train)\n",
    "    predicted = regressor.get_predicted(X_test)\n",
    "\n",
    "    # plot dignostics\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    BaseRegressorPlot.plot_predicted_vs_actual(axes[0], predicted, y_test)\n",
    "    BaseRegressorPlot.plot_learning_curves(axes[1], regressor, data_loader)\n",
    "    #plt.scatter(y_test, regressor.predict(X_test))\n",
    "    print(mean_squared_error(y_test, predicted, squared=False))\n",
    "    RMSE=mean_squared_error(y_test, predicted, squared=False)\n",
    "    RMSE_Scores.append(RMSE)\n",
    "\n",
    "\n",
    "analyze_random_forest_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper method\n",
    "This is a recursive feature elemination process to identify features importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset the data to all features\n",
    "df_fs_w = data_loader.df\n",
    "X_train_fs_w, X_test_fs_w, y_train_fs_w, y_test_fs_w = train_test_split(\n",
    "    data_loader.df_X, data_loader.df_y, test_size=0.10, random_state=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_loader.data_prep(X_train_fs_w)\n",
    "y_train = y_train_fs_w\n",
    "X_test = data_loader.data_prep(X_test_fs_w)\n",
    "y_test = y_test_fs_w\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rfe_fs(regressor, threshold=20):\n",
    "    ''' Select the most important * features based on the model\n",
    "         and use it as X_train & X_test'''\n",
    "    selector = RFE(regressor, n_features_to_select=threshold, step=1)\n",
    "    selector = selector.fit(X_train, y_train)\n",
    "    selector_ind = selector.get_support()\n",
    "    X_train_rfe = X_train.iloc[:, selector_ind]\n",
    "    X_test_rfe = X_test.iloc[:, selector_ind]\n",
    "\n",
    "    return X_train_rfe, X_test_rfe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize List to store RMSE scrores for wrapper function\n",
    "\n",
    "RMSE_Scores_Wrapper=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression()\n",
    "\n",
    "def analyze_regression():\n",
    "\n",
    "    X_train_rfe, X_test_rfe = rfe_fs(regressor)\n",
    "    regressor.fit(X_train_rfe, y_train)\n",
    "    predicted = regressor.predict(X_test_rfe)\n",
    "\n",
    "    # plot dignostics\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 8))\n",
    "    BaseRegressorPlot.plot_predicted_vs_actual(ax, predicted, y_test)\n",
    "\n",
    "  \n",
    "    print(\"RMSE = \", mean_squared_error(y_test, regressor.predict(X_test_rfe), squared=False))\n",
    "    RMSE=mean_squared_error(y_test, regressor.predict(X_test_rfe), squared=False)\n",
    "    RMSE_Scores_Wrapper.append(RMSE)\n",
    "\n",
    "\n",
    "analyze_regression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = Ridge()\n",
    "\n",
    "\n",
    "def analyze_regression():\n",
    "\n",
    "    X_train_rfe, X_test_rfe = rfe_fs(regressor)\n",
    "    regressor.fit(X_train_rfe, y_train)\n",
    "    predicted = regressor.predict(X_test_rfe)\n",
    "\n",
    "    # plot dignostics\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 8))\n",
    "    BaseRegressorPlot.plot_predicted_vs_actual(ax, predicted, y_test)\n",
    "\n",
    "    print(\"RMSE = \", mean_squared_error(y_test, regressor.predict(X_test_rfe), squared=False))\n",
    "    RMSE=mean_squared_error(y_test, regressor.predict(X_test_rfe), squared=False)\n",
    "    RMSE_Scores_Wrapper.append(RMSE)\n",
    "\n",
    "\n",
    "analyze_regression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = Lasso(alpha=0.1)\n",
    "\n",
    "def analyze_regression():\n",
    "\n",
    "    X_train_rfe, X_test_rfe = rfe_fs(regressor)\n",
    "    regressor.fit(X_train_rfe, y_train)\n",
    "    predicted = regressor.predict(X_test_rfe)\n",
    "\n",
    "    # plot dignostics\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 8))\n",
    "    BaseRegressorPlot.plot_predicted_vs_actual(ax, predicted, y_test)\n",
    "    print(\"RMSE = \", mean_squared_error(y_test, regressor.predict(X_test_rfe), squared=False))\n",
    "    RMSE=mean_squared_error(y_test, regressor.predict(X_test_rfe), squared=False)\n",
    "    RMSE_Scores_Wrapper.append(RMSE)\n",
    "\n",
    "analyze_regression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
    "\n",
    "def analyze_regression():\n",
    "\n",
    "    X_train_rfe, X_test_rfe = rfe_fs(regressor)\n",
    "    regressor.fit(X_train_rfe, y_train)\n",
    "    predicted = regressor.predict(X_test_rfe)\n",
    "\n",
    "    # plot dignostics\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 8))\n",
    "    BaseRegressorPlot.plot_predicted_vs_actual(ax, predicted, y_test)\n",
    "    print(\"RMSE = \",mean_squared_error(y_test, regressor.predict(X_test_rfe), squared=False))\n",
    "    RMSE=mean_squared_error(y_test, regressor.predict(X_test_rfe), squared=False)\n",
    "    RMSE_Scores_Wrapper.append(RMSE)\n",
    "\n",
    "analyze_regression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = DTR()\n",
    "\n",
    "def analyze_regression():\n",
    "    \n",
    "    X_train_rfe, X_test_rfe = rfe_fs(regressor)\n",
    "    regressor.fit(X_train_rfe, y_train)\n",
    "    predicted = regressor.predict(X_test_rfe)\n",
    "\n",
    "    # plot dignostics\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 8))\n",
    "    BaseRegressorPlot.plot_predicted_vs_actual(ax, predicted, y_test)\n",
    "    print(\"RMSE = \",mean_squared_error(y_test, regressor.predict(X_test_rfe), squared=False))\n",
    "    RMSE=mean_squared_error(y_test, regressor.predict(X_test_rfe), squared=False)\n",
    "    RMSE_Scores_Wrapper.append(RMSE)\n",
    "\n",
    "analyze_regression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = RFR()\n",
    "\n",
    "def analyze_regression():\n",
    "\n",
    "    X_train_rfe, X_test_rfe = rfe_fs(regressor)\n",
    "    regressor.fit(X_train_rfe, y_train)\n",
    "    predicted = regressor.predict(X_test_rfe)\n",
    "\n",
    "    # plot dignostics\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 8))\n",
    "    BaseRegressorPlot.plot_predicted_vs_actual(ax, predicted, y_test)\n",
    "    print(\"RMSE = \",mean_squared_error(y_test, regressor.predict(X_test_rfe), squared=False))\n",
    "    RMSE=mean_squared_error(y_test, regressor.predict(X_test_rfe), squared=False)\n",
    "    RMSE_Scores_Wrapper.append(RMSE)\n",
    "\n",
    "analyze_regression()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using sklearn cross_validate, set as 5 fold (same as default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cv(model): \n",
    "    score=cross_validate(model,X_train,y_train, cv=5, scoring=\"neg_mean_squared_error\")['test_score']\n",
    "    return score.mean()\n",
    "\n",
    "k_fold_cv(LinearRegression()).mean()\n",
    "\n",
    "# the model produces a metric which is  \"negate MSE\" so the larger the better. Since the metric is suppose\n",
    "# to be used not for model selection but comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor=[LinearRegression(),Ridge(),Lasso(alpha=0.1),ElasticNet(alpha=0.1, l1_ratio=0.5),DTR(),RFR()]\n",
    "\n",
    "for model in regressor:\n",
    "    score_avg=k_fold_cv(model)\n",
    "    print(\"For {model} the average neg_mean_squared_error is {scores}\".\\\n",
    "        format(model=model,scores=score_avg))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_Scores_Hyper=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = data_loader.get_clean_encoded_data()\n",
    "\n",
    "def ridge_model_HP():\n",
    "\n",
    "    parameter_space = {\n",
    "        \"alpha\": [1, 10, 100, 290, 500],\n",
    "        \"fit_intercept\": [True, False],\n",
    "        \"solver\": ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],\n",
    "    }\n",
    "\n",
    "    clf = GridSearchCV(Ridge(random_state=3), parameter_space, n_jobs=4,\n",
    "                       cv=3)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"Best parameters:\")\n",
    "    print(clf.best_params_)\n",
    "    \n",
    "    ridge_model = Ridge(random_state=3, **clf.best_params_)\n",
    "    ridge_model.fit(X_train, y_train);\n",
    "\n",
    "    y_pred = ridge_model.predict(X_test)\n",
    "    print(mean_squared_error(y_test, y_pred, squared=False))\n",
    "    RMSE=mean_squared_error(y_test, y_pred, squared=False)\n",
    "    RMSE_Scores_Hyper.append(RMSE)\n",
    "    \n",
    "ridge_model_HP()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparamter tuning of Lasso Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = data_loader.get_clean_encoded_data()\n",
    "\n",
    "def Lasso_model_HP():\n",
    "\n",
    "    parameter_space = {\n",
    "        \"alpha\":[0.0001,0.0001,0.001,0.1],\n",
    "    }\n",
    "\n",
    "    clf = GridSearchCV(Lasso(), parameter_space, n_jobs=4,cv=10)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"Best parameters:\")\n",
    "    print(clf.best_params_)\n",
    "\n",
    "    Lasso_model = Lasso(random_state=3, **clf.best_params_)\n",
    "    Lasso_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = Lasso_model.predict(X_test)\n",
    "    print(mean_squared_error(y_test, y_pred, squared=False))\n",
    "    RMSE=mean_squared_error(y_test, y_pred, squared=False)\n",
    "    RMSE_Scores_Hyper.append(RMSE)\n",
    "\n",
    "Lasso_model_HP()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning of ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = data_loader.get_clean_encoded_data()\n",
    "\n",
    "def Elastic_model_HP():\n",
    "\n",
    "    parameter_space = {\n",
    "        \"alpha\": [1, 10, 100, 280, 500],\n",
    "        \"l1_ratio\": [0.5, 1],\n",
    "        \"fit_intercept\": [True, False],\n",
    "    }\n",
    "\n",
    "    clf = GridSearchCV(ElasticNet(random_state=3), parameter_space, \n",
    "                       n_jobs=4, cv=3)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"Best parameters:\")\n",
    "    print(clf.best_params_)\n",
    "\n",
    "    elasticNet_model = ElasticNet(random_state=3, **clf.best_params_)\n",
    "\n",
    "    elasticNet_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = elasticNet_model.predict(X_test)\n",
    "    print(mean_squared_error(y_test, y_pred, squared=False))\n",
    "    RMSE=mean_squared_error(y_test, y_pred, squared=False)\n",
    "    RMSE_Scores_Hyper.append(RMSE)\n",
    "\n",
    "Elastic_model_HP()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning of Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "X_train, X_test, y_train, y_test = data_loader.get_clean_encoded_data()\n",
    "\n",
    "def DT_model_HP():\n",
    "\n",
    "    parameter_space =  {\n",
    "            \"criterion\": [\"mse\", \"friedman_mse\", \"mae\"],\n",
    "            \"min_samples_split\": [5, 18, 29, 50],\n",
    "            \"min_samples_leaf\": [3, 7, 15, 25],\n",
    "            \"max_features\": [20, 50, 150, 200, X_train.shape[1]],\n",
    "        }\n",
    "\n",
    "    clf = GridSearchCV(DecisionTreeRegressor(random_state=3), parameter_space, \n",
    "                       cv=3, n_jobs=4)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"Best parameters:\")\n",
    "    print(clf.best_params_)\n",
    "\n",
    "    dt_model = DecisionTreeRegressor(**clf.best_params_)\n",
    "\n",
    "    dt_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = dt_model.predict(X_test)\n",
    "    print(mean_squared_error(y_test, y_pred, squared=False))\n",
    "    RMSE=mean_squared_error(y_test, y_pred, squared=False)\n",
    "    RMSE_Scores_Hyper.append(RMSE)\n",
    "\n",
    "DT_model_HP()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning of Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "X_train, X_test, y_train, y_test = data_loader.get_clean_encoded_data()\n",
    "\n",
    "def RandomForest_model_HP():\n",
    "\n",
    "    parameter_space = \\\n",
    "        {\n",
    "            \"n_estimators\": [10, 100, 300, 600],\n",
    "            \"criterion\": [\"mse\", \"mae\"],\n",
    "            \"max_depth\": [7, 50, 254],\n",
    "            \"min_samples_split\": [2, 5],\n",
    "            \"min_samples_leaf\": [1, 5],\n",
    "            \"max_features\": [19, 100, X_train.shape[1]],\n",
    "            \"bootstrap\": [True, False],\n",
    "        }\n",
    "\n",
    "    clf = RandomizedSearchCV(RandomForestRegressor(random_state=3), \n",
    "                             parameter_space, cv=3, n_jobs=4, \n",
    "                             n_iter=10, random_state=3)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"Best parameters:\")\n",
    "    print(clf.best_params_)\n",
    "\n",
    "    rf_model = RandomForestRegressor(**clf.best_params_)\n",
    "\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    print(mean_squared_error(y_test, y_pred, squared=False))\n",
    "    RMSE=mean_squared_error(y_test, y_pred, squared=False)\n",
    "    RMSE_Scores_Hyper.append(RMSE)\n",
    "\n",
    "RandomForest_model_HP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = ['Linear','Ridge','Lasso','Elastic','Decision Tree','Random Forest']\n",
    "y = RMSE_Scores_Wrapper[:6]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.barh(y=range(len(x2)), tick_label=x2, width=y, height=0.4)\n",
    "plt.xlim(25000,45000)\n",
    "ax.set(xlabel=\"RMSE (smaller is better)\", ylabel=\"Model: Wrapper Function\")\n",
    "\n",
    "x1 = ['Linear','Ridge','Lasso','Elastic','Decision Tree','Random Forest']\n",
    "y = RMSE_Scores[:6]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.barh(y=range(len(x1)), tick_label=x1, width=y, height=0.4)\n",
    "plt.xlim(25000,45000)\n",
    "ax.set(xlabel=\"RMSE (smaller is better)\", ylabel=\"Model: Clean_encoded_data\")\n",
    "\n",
    "\n",
    "RMSE_Scores_Hyper.insert(0,0)\n",
    "x3 = ['Linear','Ridge','Lasso','Elastic','Decision Tree','Random Forest']\n",
    "y = RMSE_Scores_Hyper[-6:]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.barh(y=range(len(x3)), tick_label=x3, width=y, height=0.4)\n",
    "plt.xlim(25000,45000)\n",
    "ax.set(xlabel=\"RMSE (smaller is better)\", ylabel=\"Model: Hyperparameter Tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "            'Regressor': x1,\n",
    "            'Wrapper':RMSE_Scores_Wrapper[:6],\n",
    "            'Baseline': RMSE_Scores[:6],\n",
    "            'Hyperparameter_tuning':RMSE_Scores_Hyper[-6:]\n",
    "            })\n",
    "df = df.style.set_caption('Comparison of RMSE Scores for various Regressors with, Baseline, Wrapper Function and Hyperparameter tuning')\n",
    "display(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
